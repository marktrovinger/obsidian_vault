## Dr. Mittal
### Overlap
- Interpretability
	- How do we know that models are learning the things we want them to learn?
	- Are the underlying structures that arise during training a useful method for determining if a model is learning correctly?
	- Interpretability and RL
		- General interpretability tools for all (or most) Transformer based models
	- NLP Interpretability
		- Investigate how structures form

## Dr. Rahimi
### Overlap
- RL
	- Has published papers in RL in the past, using RL to tune AI opponents
	- Has also used RL as an augment, mostly in the area of game theory
		- Extend existing approaches in game theory using RL or apply game theory to RL?
	- If an interesting enough research question is posed for RL, will he be interested?
		- Maybe? 
	- Possible ideas:
		- Further extend the work done in MS, build a more robust or general version of DT?
			- Extend both the environment and GPT components to generalize across observation and state spaces, also modularize (if needed) the type of GPT that is used
			- Fix shortcoming present in DT, make it more sample-efficient, how well do Transformer based models perform in limited sample benchmarks like Atari 100k?
			- Investigate how the various components of Transformers would benefit from hyper-parameter tuning, would it need to be based on the environment?
		- Environment/Tooling Projects
			- Based on comment made by Suarez, potentially lots of low-hanging fruit present in fixing parallelization code
			- Discuss with Suarez possibility of env/tooling research project at the PhD level
## Dr. Chen
### Overlap
- Robotics and RL
	- Transformer-based models would be an interesting avenue of research if he wishes to move into planning/semi-autonomous robotics
	- Environment development
		- What environments currently exist (if any) currently exist for the types of terrains that the robots are planned?
	- 