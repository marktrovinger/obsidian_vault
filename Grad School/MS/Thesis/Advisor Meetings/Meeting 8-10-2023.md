## Pre-Meeting Notes
### Thesis:
- Results so far:
	- Expert level data is performing better
	- Running for 5 epochs, looking at tuning of hyperparameters
	- DT performs better in discrete action spaces than multi-discrete
	- Looking at analysis for why we are seeing these results
	- Effect of positional encoding vs. no positional encoding
- Spread of data across training run is working, needs some tweaks
- More sections have been completed (for first draft) of the document itself
- Question about figures
	- What should the graph look like for performance?
- Prelim results from full sweep, but need to investigate underlying data first, doing that this week
- Citations (among other things) are working in the LaTeX document, thanks to Mark Senn at Purdue
- Adding section in results for expert data vs. non-optimal, along with an analysis of the behavior
- Should the second chapter be a background and lit review chapter?

### In progess:
- Making code more generalizable; moving away from "magic" numbers to computed values
- Making code more user friendly, adding command line flags


### Paper:
- Venue options: 
	- CoRL 2023 deadline was in June, so thats out
	- JMLR is an option
		- Looking into what is needed for submission
		- Might be the best bet, if that strikes out we can always look elsewhere
	- RLDM might also work
	- ICML 2024 would be a possibility
	- ICLR 2024 as well