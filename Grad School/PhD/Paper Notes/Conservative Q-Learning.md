# Tasks
- Paper reading, making sure I am taking the best notes possible, also referring to code whenever possible
- Code environment created, D4RL environment only, for faster processing

# Insight
- Regularizes the Q-values during training
- Learns a lower bound on the $Q$-function


# Related Work
## Approaches
- Limits the learned policy to be close to behavior policy
	- KL Divergence: 
	- Wasserstein Distance:
	- MMD: 
- Bootstrapping a behavior policy: 
- Q-function penalties