### General
- 2023
- code: https://github.com/RyanNavillus/PPO-v3
### Contributions
- Used DreamerV3's stability techniques for PPO
- High quality implementation in CleanRL
- Demonstration of the Dreamer tricks (detail these tricks)
- Analysis of the tricks

### Limitations
- lack of environment variability

### Possible Future Work
- Use in a robust setting?